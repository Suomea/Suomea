#Kafka

Topic 是一个主题，任何生产者都可以往 topic 中发送数据。

Partition 是一个分区，一个 topic 可以有多个分区，每个分区包含主题中的一部分数据。

Consumer Group 是消费者组，消费者属于消费者组。

![[Kafka-ConsumerGroup.png]]

## 消费者配置
**auto.offset.reset**
该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长 时间失效，包含偏移量的记录已经过时并被删除）该作何处理。它的默认值是 `latest`，意思是说，在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。另一个值是 `earliest`，意思是说，在偏移量无效的情况下，消费者将从起始位置读取分区的记录。

**enable.auto.commit** 
该属性指定了消费者是否自动提交偏移量，默认值是 true。为了尽量避免出现重复数据和数据丢失，可以把它设为 false，由自己控制何时提交偏移量。如果把它设为 true，还可以通过配置 `auto.commit.interval.ms` 属性来控制提交的频率。

Kafka 消费者通过 poll() 拉取分区里面的消息进行消费，默认情况消费者默认不需要确认消费，而是每过一段时间把自己从 poll() 接收到的最大偏移量提交上去（有可能已经提交了偏移量，但是还没有消费处理完成）。自动提交由 `enable.auto.commit` 控制，频率由 `auto.commit.interval.ms` 控制，默认 5s。

重复消费的情况，如果上一次提交偏移量之后，消费者又消费了一些消息但是还没有来得及提交，消费者重启会导致 poll() 拉取已经消费过的消息。

消息丢失的情况，如果上一次提交偏移量之后，消费者还没消费完偏移量之前的消息，消费者重启 poll() 只会拉取偏移量之后的消息，导致消息丢失。

关闭 `enable.auto.commit`，使用 `commitSync()` 方法进行同步手动提交，能够解决消息丢失的问题。但是仍不能避免消息重复的问题，因为提交有可能失败，导致重复消费。