---
comments: true
---

通过对多线程的介绍，能够到了并发编程一个最基本的问题：即希望原子性的执行一系列指令，但是由于单处理器的中断（或者多个线程在多个处理器上执行），我们做不到。

通过锁（lock），直接解决这一问题。在程序代码中加锁，放在临界区周围，保证临界区能够像单条原子指令一样执行。
## Pthread 锁
POSIX 库将锁称为互斥量（mutex），因为它被用来提供线程之间的互斥。即当一个线程在临界区，它能够阻止其它线程进入直到当前线程离开临界区。

```c
#include <pthread.h>

int pthread_mutex_init(pthread_mutex *mutex, const pthread_mutexattr_t *mutexattr);

int pthread_mutex_lock(pthread_mutex_t *mutex);

int pthread_mutex_unlock(pthread_mutex_t *mutex);

int pthread_mutex_destory(pthread_mutex_t *mutex);
```

这些函数在成功时返回 0，失败时返回错误代码，所以必须对函数的返回代码进行检查。这些函数的参数都是一个先前声明过的对象的指针，类型为 pthread_mutex_t。pthread_mutex_init 函数中的属性允许设置互斥量的属性，互斥量的属性控制着互斥量的行为。

## 如何实现锁
首先需要明确的是，锁的实现需要硬件和操作系统的帮助。各种计算机体系结构的指令集都包含一些相似的硬件原语，这里不研究这些指令是如何实现的，只研究如何使用它们来实现锁这样的互斥原语。操作系统正是在这种基础指令的支持下完善发展，支持实现复杂成熟锁库的。

### 评价锁
在实现锁之前，应该明确目标，即如何评价一种锁实现的效果，应该为此设立一些明确的目标。

- 正确性，锁是否能够完成它的基本任务，即提供互斥。这是最基本的，锁是否有效，能够阻止多个线程进入临界区。
- 公平性，当锁可用时，是否每一个竞争线程有公平的机会抢到锁？用另一种极端的方式看这个问题是，是否有竞争的线程会饿死，一致无法获得锁？
- 性能，具体来说，是使用锁之后增加的时间开销。

### 简单的尝试
我们的想法很简单：用一个变量来标志锁是否被某些线程占用。

第一个线程进入临界区，调用 lock 函数，检查标志是否为 1（这里不是 1），然后设置标志为 1，表示线程持有该锁。结束临界区时，线程调用 unlock 函数，清除标志，表示锁未被持有。

线程在等待已经被持有的锁时，采用了自旋等待的技术（spin waiting），就是不停的检查锁标志的值。
```c
struct my_lock {
    int flag;
} mutex;

void init(struct my_lock *mutex) {
    mutex->flag = 0;
}

void lock(struct my_lock *mutex) {
    while (mutex->flag == 1)    // test the flag
        ;   // spain wait
    mutex->flag = 1;    // set the flag
}

void unlock(struct my_lock *mutex) {
    mutex->flag = 0;
}
```
遗憾的是这段代码有两个问题：正确性和性能。

**正确性问题**
一种是不可控的线程调度，因为 lock 函数加锁的逻辑分为两步并且线程的调度不可控，可能会导致两个线程同时加锁成功。我们需要可靠的原子操作（guaranteed atomic operations）来解决这个问题。

| Thread 1                          | Thread 2                                        |
| --------------------------------- | ----------------------------------------------- |
| test the flag; // 中断：切换到 Thread 2 |                                                 |
|                                   | test the flag; set the flag; // 中断：切换到 Thread 1 |
| set the flag;                     |                                                 |

另一种是线程模型（或者 CPU 缓存模型）使得变量缓存在线程本地（或者 CPU 缓存），导致即使一个线程加锁成功而另一个线程观察不到仍能加锁成功。可以通过总线加锁（LOCK# 信号和 LOCK 指令前缀）来解决这个问题。

同时为了使临界区的代码执行完成之后，所有的线程都能观察到临界区对状态的更新，一般使用内存屏障相关的指令来保证状态的可视性。需要注意这里的状态可视性和锁变量的可视性要区分开。

**性能问题**
性能问题主要是自旋等待在等待其它线程释放锁的时候会浪费 CPU 时间。尤其是在单处理器上，一个等待线程等待的目标线程甚至无法运行！

### 硬件原语 test-and-set
尽管简单的尝试想法很好，但是没有硬件的支持是无法实现的。幸运的是，一些系统提供了这一指令，支持基于这种概念创建简单的锁。

在 x86 上，是 xchg（atomic change，原子交换）指令，该指令自动带有 LOCK 语义，通常称为测试并设置指令（test-and-set）。使用 C 代码来定义测试并设置指令做了什么。
```c
int TestAndSet(int *old_ptr, int new) {
    int old = *old_ptr;
    *old_ptr = new;
    return old;
}
```

使用 xchg 的简单自旋锁如下：
```c
typedef struct my_lock {
    int flag;
} mutex;

void init(struct my_lock *mutex) {
    mutex->flag = 0;
}

void lock(struct my_lock *mutex) {
    while(TestAndSet(mutex->flag, 1) == 0)
        ;
}

void unlock(struct my_lock *mutex) {
    mutex->flag = 0;
}
```
这种锁的实现称为自旋锁，是一种最简单的锁，一值自旋，直到锁可用。

### 硬件原语 compare-and-swap
另一个硬件原语是比较并交换指令，x86 架构中是 cmpxchgl 指令。C 语言伪代码如下：
```c
int CompareAndSwap(int *ptr, int expected, int new) {
    int actual = *ptr;
    if(actual == expected) {
        *ptr = new;
    }
    return actual;
}
```
有了比较并交换指令，就可以实现一个锁，类似于测试并设置那样。例如，只需要用下面的代码替换 lock() 函数：
```c
void lock(my_lock *mutex) {
    while(CompareAndSwap(mutex->flag, 0, 1) == 0) {
        ;
    }
}
```
下面是通过 cmpxchgl 指令实现锁并通过测试的真实示例，代码中使用到了内联汇编的语法：
```c
#include <stdio.h>
#include <assert.h>
#include <pthread.h>

char CompareAndSwap(int *ptr, int old, int new) {
    unsigned char ret;

    __asm__ __volatile__ (
            " lock\n"   // lock
            " cmpxchgl %2, %1\n"    // cmpxchgl
            " sete %0\n"    // sete
            : "=q" (ret), "=m" (*ptr)   // 输出
            : "r" (new), "a" (old)  // 输入
            : "memory");    // memory
    return ret;
}

struct my_lock {
    int flag;
} mutex;

void init(struct my_lock *mutex) {
    mutex->flag = 0;
}

void lock(struct my_lock *mutex) {
    while(CompareAndSwap(&mutex->flag, 0, 1) == 0) {
        ;
    }
}

void unlock(struct my_lock *mutex) {
    mutex->flag = 0;
}

int counter = 0;

void *thread_function(void *arg);

int main() {
    pthread_t a_thread, b_thread;
    int rc;

    init(&mutex);

    printf("main: begin\n");

    rc = pthread_create(&a_thread, NULL, thread_function, "A"); assert(rc == 0);
    rc = pthread_create(&b_thread, NULL, thread_function, "B"); assert(rc == 0);

    rc = pthread_join(a_thread, NULL); assert(rc == 0);
    rc = pthread_join(b_thread, NULL); assert(rc == 0);

    printf("main: done with both (counter = %d)\n", counter);

    return 0;
}

void *thread_function(void *arg) {
    printf("%s: begin\n", (char *) arg);
    for(int i = 0; i < 1000000; i ++) {
        lock(&mutex);
        counter ++;
        unlock(&mutex);
    }
    printf("%s: done\n", (char *) arg);

    return NULL;
}
```
这里解释一下内联汇编部分的代码。

1. `lock` 标识锁定内存总线，并且保证后的指令原子式的执行。
2. 输入部分 `"a" (old)` 表示将 `old` 变量的值放入 `eax` 寄存中作为汇编指令的输入。`a` 表示 `eax` 寄存器。
3. 输入部分 `"r" (new)` 表示将 `new` 变量的值使用一个通用寄存器存放，作为汇编指令的输入。`r` 表示任意的一个通用寄存器。占位 `%2`。
4. 输出部分 `"=m" (*ptr)` 表示使用内存地址（`*ptr`）作为汇编指令的输出，`m` 表示内存地址，`=` 表示输出表达式操作是只写的。占位 `%1`。
5. 输出部分 `"=q" (ret)` 暂时没有搞明白，大致就是输出结果放到 `ret` 中。占位 `%0`。
6. `cmpxchgl` 指令比较 `eax` 寄存的值（也就是 `old` 变量的值）与 `%1` 占位的值（也就是 `*ptr` 的值），如果相等，将 `%2` 占位的值（也就是 `new` 变量的值）
    赋值给 `%1` 占位（也就是 `*ptr`）同时标志寄存器 `ZF` 位置 `1`；否则，将 `%1` 占位的值赋值给 `eax`，并且将标志寄存器 `ZF` 位置 `0`。
7. `sete` 指令，如果标志寄存器 `ZF` 位为 `1` 那么设置 `%0` 占位的值（也就是 `ret` 的值）为 `1`。
8. `memory` 向 GCC 声明：在这里内存发生或者可能发生可改变。那么 GCC 会保证在此内联汇编之前如果某个内存的内容被读取，那么在内联汇编之后如果需要使用
   使用这个内存处的内容，就会直接从内存读取而不是使用缓存，从而实现内存屏障的效果。

### 硬件原语 fetch-and-add
获取并增加指令能够原子地返回特定地址的旧值，并且让该值自增一。使用该指令也能实现简单的自旋锁，这里我们增加一点玩法，在自旋的基础上实现公平性。
```c
int FetchAndAdd(int *ptr) {
    int old = *ptr;
    *ptr ++;
    return old;
}

typedef struct my_lock {
    int ticket;
    int turn;
} mutex;

void init(struct my_lock *mutex) {
    mutex->ticket = 0;
    mutex->turn = 0;
}

void lock(struct my_lock *mutex) {
    int my_turn = FetchAndAdd(&mutex->ticket);
    while(mutex->turn != my_turn) {
        ;
    }
}

void unlock(struct my_lock *mutex) {
    FetchAndAdd(&mutex->turn);
}
```
不同于之前的方法，这种方式能够保证只要一个线程获取了 ticket 值，它最终会被调度。

## 如何解决过多的自旋
通过上述硬件原语，已经实现了正确、公平的锁，但是通过使用自旋等待实现的锁可能会造成性能问题。  

在并发量较少且临界区能够快速执行完毕的情况下 可能问题不明显；在果并发量比较高或者临界区耗时比较久的情况下，如果临界区的线程（获得锁的线程）发生上下文切换，那么其它线程即使获得 CPU 时间
也只能一直自旋等待，浪费了 CPU 时间。

### 线程让步
一种简单的的方法使在线程要自旋的时候让出 CPU，参考下面的代码：
```c
void lock(my_lock *mutex) {
    while(TestAndSet(&mutex->flag, 1) == 1)
	    yield();
}
```

在这种方法中，假定操作系统提供原语 `yield()`，线程可以调用它主动放弃 CPU，让其它线程运行。

在许多线程竞争同一把锁的情况下，线程让步就不太好了。比如 100 个线程竞争一把锁，在这种情况下，一个线程持有锁，在释放锁之前，其它 99 个线程分别调用 `lock()`，发现锁被抢占，然后让出 CPU。问题是，竞争线程虽然让出了 CPU，但是让出之后处于就绪状态，仍能获取 CPU 时间。那么上下文切换，甚至极端情况下一个线程可能一直处于让出循环，锁的性能仍然很低。

### 休眠代替自旋
自旋和线程让步真正的问题是存在太多的偶然性，导致在较多线程时，锁的性能较低。因此，可以施加一些控制，并且在决定释放锁时定能抢到锁。为了做到这一点，需要操作系统提供更多的支持，并需要一个队列来保存等待锁的线程。

Solaris 系统提供了两个系统调用：park() 能够让调用线程休眠，unpark(threadID) 则会唤醒 threadID 标识的线程。

示例代码：
```c
typedef struct lock_t {
    int flag;
    int guard;
    queue_t *q;
} lock_t;

void lock_init(lock_t *m) {
    m->flag = 0;
    m->guard = 0;
    queue_init(m->q);
}

void lock(lock_t *m) {
    while(TestAndSet(&m->guard, 1) == 1)
        ;   // acquire guard lock by spinning

    if(m->flag == 0) {
        m->flag = 1;
        m->guard = 0;
    } else {
        queue_add(m->q, gettid());
        m->guard = 0;
        park();
    }
}

void unlock(lock_t *m) {
    while(TestAndSet(&m->guard, 1) == 1)
        ; // acquire guard lock by spinning
    
    if(queue_empty(m->q)) {
        m->flag = 0;
    } else {
        unpark(queue_remove(m->q));
    }

    m->guard = 0;
}
```

上述代码 guard 基本上起到了自旋锁的作用，围绕着 flag 和队列操作。线程设置 guard 成功后，会设置 flag，之后释放 guard。新的线程设置 guard 成功之后会判断 flag 的值，判断当前是否有其它线程已经获得锁，如果有则 park() 进入休眠状态，等待 unpark() 唤醒。

当唤醒另一个线程时，flag 并没有设置为 0。线程被唤醒时，就像是从 park() 调用返回。就像把锁从释放的线程传递给下一个获得锁的线程，直到队列为空才将 flag 设置为 0。

在 park() 调用之前，如果不凑巧，一个线程将要 park()，此时切换到另一个线程，比如持有锁的线程，执行了释放锁的代码。那么前一个线程的 park() 将会永远休眠。这种问题称为唤醒/等待竞争（wakeup/waiting race）， Solaris 通过增加 setpark() 系统调用来解决这一问题。通过 setpark()，一个线程表明自己马上要 park，如果刚好另一个线程被调度，并且调用了 unpark()，那么后续的 park() 调用会直接返回，而不是一直睡眠。lock() 函数可以做一点小修改：
```c
queue_add(m->q, gettid());
setpark();
m->guard = 0;
park();
```

这段代码还有一些问题，如何确保 flag 和 guard 以及 queue_t 的可视性？

### Linux futex
Linux 提供了快速用户空间互斥量（fast userspace mutex，futex），每个 futex 都关联一个特定的物理内存位置，也有一个事先建好的内核队列。

有两个系统调用：`futex_wait(address，expected)` ，如果 `address` 处的值等于 `expected`，就会让线程睡眠，否则立刻返回；`futex_wake(address)` 唤醒等待队列中的一个线程。

futex 利用一个整数，同时记录锁是否被持有（整数的最高位），以及等待锁的个数（整数的其余所有位）。因此，如果锁是负的，它就被持有。

```c
void mutex_lock(int *mutex)
{
    int v;
    /* Bit 31 was clear, we got the mutex (the fastpath) */
    if (atomic_bit_test_set(mutex, 31) == 0)
        return;
    atomic_increment(mutex);
    while (1)
    {
        if (atomic_bit_test_set(mutex, 31) == 0)
        {
            atomic_decrement(mutex);
            return;
        }
        /* We have to waitFirst make sure the futex value
        we are monitoring is truly negative (locked). */
        v = *mutex;
        if (v >= 0)
            continue;
        futex_wait(mutex, v);
    }
}

void mutex_unlock(int *mutex)
{
    /* Adding 0x80000000 to counter results in 0 if and
    only if there are not other interested threads */
    if (atomic_add_zero(mutex, 0x80000000))
        return;

    /* There are other threads waiting for this mutex,
    wake one of them up. */
    futex_wake(mutex);
}
```

`atomic_bit_test_set()` 函数将指定的位设置为 1，并返回原来的值。示例代码中将最高位设置为 1，成功表示获取锁，同时 `*mutex` 称为负数。

`atomic_add_zero()` 将两个数相加，并判断结果是不是 0。示例代码中该函数的作用是释放锁，并且如果结果等于 0 表示没有等待的线程，直接返回。

## 基于锁的并发数据结构

### 计数器

### 链表

### 队列

### 散列表
### QA
1. 如何实现可重入的锁？

2. 为什么汇编指令需要加上 LOCK 前缀？

3. 如何实现读写锁？

4. Java 通过锁能够实现互斥访问，但是执行完临界区的代码之后如何保证全局变量的可视性？

    如果一个线程解锁，那么紧跟着加锁的线程是能够看到上一个线程的改变的，由 Happen-before 规则约束。
    那么 Happen-before 底层又是如果实现的呢？https://gee.cs.oswego.edu/dl/jmm/cookbook.html

5. Java 对象头的结构是什么？在由无锁->轻量级锁->重量级锁过程中 CAS 的参数是什么？如何获取这些参数？